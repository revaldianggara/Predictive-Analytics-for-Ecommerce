{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_dataset_path': 'data/raw',\n",
       " 'data_set_path': 'data/output/data.pkl',\n",
       " 'input_set_path': 'data/output/input.pkl',\n",
       " 'output_set_path': 'data/output/output.pkl',\n",
       " 'input_columns_path': 'data/output/input_columns.pkl',\n",
       " 'train_set_path': ['data/output/X_train.pkl', 'data/output/y_train.pkl'],\n",
       " 'valid_set_path': ['data/output/X_valid.pkl', 'data/output/y_valid.pkl'],\n",
       " 'test_set_path': ['data/output/X_test.pkl', 'data/output/y_test.pkl'],\n",
       " 'output_column': 'category_encoded',\n",
       " 'seed': 42,\n",
       " 'test_size': 0.2,\n",
       " 'standardizer_path': 'data/output/standardizer.pkl',\n",
       " 'preprocessor_path': 'data/output/preprocessor.pkl',\n",
       " 'train_clean_path': ['data/output/X_train_clean.pkl',\n",
       "  'data/output/y_train_clean.pkl'],\n",
       " 'valid_clean_path': ['data/output/X_valid_clean.pkl',\n",
       "  'data/output/y_valid_clean.pkl'],\n",
       " 'test_clean_path': ['data/output/X_test_clean.pkl',\n",
       "  'data/output/y_test_clean.pkl'],\n",
       " 'list_of_model_path': 'log/list_of_model.pkl',\n",
       " 'list_of_param_path': 'log/list_of_param.pkl',\n",
       " 'list_of_tuned_model_path': 'log/list_of_tuned_model.pkl',\n",
       " 'best_model_path': 'models/best_model.pkl',\n",
       " 'best_threshold_path': 'models/best_threshold.pkl'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_DATA = utils.config_load()\n",
    "CONFIG_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buat Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of model\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231    0\n",
       "374    3\n",
       "55     1\n",
       "381    3\n",
       "70     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = utils.pickle_load(CONFIG_DATA['test_clean_path'][1])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define param\n",
    "def create_model_param():\n",
    "    \"\"\"Create the model objects\"\"\"\n",
    "    # knn_params = {\n",
    "    #     'n_neighbors': [50, 100, 200],\n",
    "    # }\n",
    "    \n",
    "    rf_params = {\n",
    "        \"n_estimators\" : [i for i in range(50, 151, 30)],\n",
    "        \"min_samples_split\" : [2, 4, 6, 8],\n",
    "        \"criterion\" : [\"gini\", \"entropy\", \"log_loss\"]\n",
    "    }\n",
    "\n",
    "    # lgr_params = {\n",
    "    #     # 'penalty': ['l1', 'l2'],\n",
    "    #     'C': [0.01, 0.1],\n",
    "    #     'max_iter': [100, 300, 500]\n",
    "    # }\n",
    "\n",
    "    xgb_params = {\n",
    "        'n_estimators': [5, 10, 25, 50]\n",
    "    }\n",
    "\n",
    "    # gbc_params = {\n",
    "    #     'n_estimators': [50, 100, 150],\n",
    "    #     'learning_rate': [0.01, 0.1, 0.2],\n",
    "    #     'max_depth': [3, 5, 7]\n",
    "    # }\n",
    "    \n",
    "    # lgbm_params = {\n",
    "    #     'n_estimators': [50, 100, 150],\n",
    "    #     'learning_rate': [0.01, 0.1, 0.2],\n",
    "    #     'num_leaves': [31, 63, 127],\n",
    "    #     'min_child_samples': [20, 40, 60]\n",
    "    # }\n",
    "\n",
    "\n",
    "    # Create model params\n",
    "    list_of_param = {\n",
    "        # 'KNeighborsClassifier': knn_params,\n",
    "        'RandomForestClassifier': rf_params,\n",
    "        # 'LogisticRegression': lgr_params,\n",
    "        'XGBClassifier': xgb_params,\n",
    "        # 'GradientBoostingClassifier': gbc_params,\n",
    "        # 'LGBMClassifier': lgbm_params\n",
    "    }\n",
    "\n",
    "    return list_of_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_object():\n",
    "    \"\"\"Create the model objects\"\"\"\n",
    "    print(\"Creating model objects\")\n",
    "\n",
    "    # Create model objects\n",
    "    rf = RandomForestClassifier()\n",
    "    xgb = XGBClassifier()\n",
    "\n",
    "    # Create list of model\n",
    "    list_of_model = [\n",
    "        {'model_name': rf.__class__.__name__, 'model_object': rf},\n",
    "        {'model_name': xgb.__class__.__name__, 'model_object': xgb}\n",
    "    ]\n",
    "\n",
    "    return list_of_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model objects\n"
     ]
    }
   ],
   "source": [
    "list_of_param = create_model_param()\n",
    "list_of_model = create_model_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestClassifier': {'n_estimators': [50, 80, 110, 140],\n",
       "  'min_samples_split': [2, 4, 6, 8],\n",
       "  'criterion': ['gini', 'entropy', 'log_loss']},\n",
       " 'XGBClassifier': {'n_estimators': [5, 10, 25, 50]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_name': 'RandomForestClassifier',\n",
       "  'model_object': RandomForestClassifier()},\n",
       " {'model_name': 'XGBClassifier',\n",
       "  'model_object': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "                gamma=None, grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "                num_parallel_tree=None, random_state=None, ...)}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def train_model(return_file=True):\n",
    "    \"\"\"Function to get the best model\"\"\"\n",
    "    # Load dataset\n",
    "    X_train = utils.pickle_load(CONFIG_DATA['train_clean_path'][0])\n",
    "    y_train = utils.pickle_load(CONFIG_DATA['train_clean_path'][1])\n",
    "    X_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'][0])\n",
    "    y_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'][1])\n",
    "    \n",
    "    # Create list of params & models\n",
    "    list_of_param = create_model_param()\n",
    "    list_of_model = create_model_object()\n",
    "\n",
    "    # List of trained model\n",
    "    list_of_tuned_model = {}\n",
    "    \n",
    "    # Define StratifiedKFold for cross-validation\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=123) \n",
    "\n",
    "    # Train model\n",
    "    for base_model in list_of_model:\n",
    "        # Current condition\n",
    "        model_name = base_model['model_name']\n",
    "        model_obj = copy.deepcopy(base_model['model_object'])\n",
    "        model_param = list_of_param[model_name]\n",
    "\n",
    "        # Debug message\n",
    "        print('Training model :', model_name)\n",
    "\n",
    "        # Create model object\n",
    "        model = RandomizedSearchCV(estimator = model_obj,\n",
    "                                   param_distributions = model_param,\n",
    "                                   n_iter=5,\n",
    "                                   cv=skf,  # Use StratifiedKFold\n",
    "                                   random_state = 123,\n",
    "                                   n_jobs=1,\n",
    "                                   verbose=10,\n",
    "                                   scoring = 'accuracy')\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        # y_pred_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "        # y_pred_proba_valid = model.predict_proba(X_valid)[:, 1]\n",
    "        \n",
    "        # Prediksi probabilitas & calculate AUC score\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_valid = model.predict(X_valid)\n",
    "\n",
    "        # Menghitung AUC dengan asumsi klasifikasi multi-kelas\n",
    "        \n",
    "        ''' \n",
    "        One vs One: OvO lebih cocok untuk dataset yang lebih kecil karena lebih sedikit data yang digunakan pada masing-masing klasifikator, \n",
    "        sementara One-vs-Rest (OvR) / One-vs-All (OvA) lebih efisien dalam hal waktu komputasi untuk dataset yang besar atau dengan banyak kelas.\n",
    "        '''\n",
    "        cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "        cm_valid = confusion_matrix(y_valid, y_pred_valid)\n",
    "        acc_train = accuracy_score(y_train, y_pred_train)\n",
    "        acc_valid = accuracy_score(y_valid, y_pred_valid)\n",
    "\n",
    "        # Append\n",
    "        list_of_tuned_model[model_name] = {\n",
    "            'model': model,\n",
    "            'train_cm': cm_train,\n",
    "            'valid_cm': cm_valid,\n",
    "            'train_accuracy': acc_train,\n",
    "            'valid_accuracy': acc_valid,\n",
    "            'best_params': model.best_params_\n",
    "        }\n",
    "\n",
    "        print(\"Done training\")\n",
    "        print(\"\")\n",
    "\n",
    "    # Dump data\n",
    "    utils.pickle_dump(list_of_param, CONFIG_DATA['list_of_param_path'])\n",
    "    utils.pickle_dump(list_of_model, CONFIG_DATA['list_of_model_path'])\n",
    "    utils.pickle_dump(list_of_tuned_model, CONFIG_DATA['list_of_tuned_model_path'])\n",
    "\n",
    "    if return_file:\n",
    "        return list_of_param, list_of_model, list_of_tuned_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model objects\n",
      "Training model : RandomForestClassifier\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV 1/3; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 1/3; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.908 total time=   0.0s\n",
      "[CV 2/3; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 2/3; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.974 total time=   0.0s\n",
      "[CV 3/3; 1/5] START criterion=entropy, min_samples_split=2, n_estimators=110....\n",
      "[CV 3/3; 1/5] END criterion=entropy, min_samples_split=2, n_estimators=110;, score=0.842 total time=   0.0s\n",
      "[CV 1/3; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 1/3; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.921 total time=   0.0s\n",
      "[CV 2/3; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 2/3; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.921 total time=   0.0s\n",
      "[CV 3/3; 2/5] START criterion=gini, min_samples_split=8, n_estimators=80........\n",
      "[CV 3/3; 2/5] END criterion=gini, min_samples_split=8, n_estimators=80;, score=0.855 total time=   0.0s\n",
      "[CV 1/3; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 1/3; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.908 total time=   0.1s\n",
      "[CV 2/3; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 2/3; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.947 total time=   0.0s\n",
      "[CV 3/3; 3/5] START criterion=entropy, min_samples_split=6, n_estimators=110....\n",
      "[CV 3/3; 3/5] END criterion=entropy, min_samples_split=6, n_estimators=110;, score=0.855 total time=   0.1s\n",
      "[CV 1/3; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 1/3; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.921 total time=   0.1s\n",
      "[CV 2/3; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 2/3; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.934 total time=   0.1s\n",
      "[CV 3/3; 4/5] START criterion=entropy, min_samples_split=8, n_estimators=140....\n",
      "[CV 3/3; 4/5] END criterion=entropy, min_samples_split=8, n_estimators=140;, score=0.868 total time=   0.1s\n",
      "[CV 1/3; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 1/3; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.921 total time=   0.0s\n",
      "[CV 2/3; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 2/3; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.987 total time=   0.0s\n",
      "[CV 3/3; 5/5] START criterion=gini, min_samples_split=6, n_estimators=110.......\n",
      "[CV 3/3; 5/5] END criterion=gini, min_samples_split=6, n_estimators=110;, score=0.868 total time=   0.0s\n",
      "Done training\n",
      "\n",
      "Training model : XGBClassifier\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3; 1/4] START n_estimators=5..............................................\n",
      "[CV 1/3; 1/4] END ...............n_estimators=5;, score=0.868 total time=   0.0s\n",
      "[CV 2/3; 1/4] START n_estimators=5..............................................\n",
      "[CV 2/3; 1/4] END ...............n_estimators=5;, score=0.855 total time=   0.0s\n",
      "[CV 3/3; 1/4] START n_estimators=5..............................................\n",
      "[CV 3/3; 1/4] END ...............n_estimators=5;, score=0.908 total time=   0.0s\n",
      "[CV 1/3; 2/4] START n_estimators=10.............................................\n",
      "[CV 1/3; 2/4] END ..............n_estimators=10;, score=0.895 total time=   0.0s\n",
      "[CV 2/3; 2/4] START n_estimators=10.............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dtsre\\miniconda3\\envs\\global\\lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 2/4] END ..............n_estimators=10;, score=0.934 total time=   0.0s\n",
      "[CV 3/3; 2/4] START n_estimators=10.............................................\n",
      "[CV 3/3; 2/4] END ..............n_estimators=10;, score=0.908 total time=   0.0s\n",
      "[CV 1/3; 3/4] START n_estimators=25.............................................\n",
      "[CV 1/3; 3/4] END ..............n_estimators=25;, score=0.934 total time=   0.0s\n",
      "[CV 2/3; 3/4] START n_estimators=25.............................................\n",
      "[CV 2/3; 3/4] END ..............n_estimators=25;, score=0.974 total time=   0.0s\n",
      "[CV 3/3; 3/4] START n_estimators=25.............................................\n",
      "[CV 3/3; 3/4] END ..............n_estimators=25;, score=0.895 total time=   0.0s\n",
      "[CV 1/3; 4/4] START n_estimators=50.............................................\n",
      "[CV 1/3; 4/4] END ..............n_estimators=50;, score=0.921 total time=   0.0s\n",
      "[CV 2/3; 4/4] START n_estimators=50.............................................\n",
      "[CV 2/3; 4/4] END ..............n_estimators=50;, score=0.987 total time=   0.0s\n",
      "[CV 3/3; 4/4] START n_estimators=50.............................................\n",
      "[CV 3/3; 4/4] END ..............n_estimators=50;, score=0.882 total time=   0.0s\n",
      "Done training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_param, list_of_model, list_of_tuned_model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestClassifier': {'model': RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=123, shuffle=True),\n",
       "                     estimator=RandomForestClassifier(), n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'criterion': ['gini', 'entropy',\n",
       "                                                        'log_loss'],\n",
       "                                          'min_samples_split': [2, 4, 6, 8],\n",
       "                                          'n_estimators': [50, 80, 110, 140]},\n",
       "                     random_state=123, scoring='accuracy', verbose=10),\n",
       "  'train_cm': array([[57,  0,  0,  0],\n",
       "         [ 0, 57,  0,  0],\n",
       "         [ 0,  1, 55,  1],\n",
       "         [ 0,  0,  0, 57]], dtype=int64),\n",
       "  'valid_cm': array([[ 8,  0,  0,  0],\n",
       "         [ 0, 20,  3,  0],\n",
       "         [ 0,  0, 30,  1],\n",
       "         [ 0,  2,  1, 24]], dtype=int64),\n",
       "  'train_accuracy': 0.9912280701754386,\n",
       "  'valid_accuracy': 0.9213483146067416,\n",
       "  'best_params': {'n_estimators': 110,\n",
       "   'min_samples_split': 6,\n",
       "   'criterion': 'gini'}},\n",
       " 'XGBClassifier': {'model': RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=123, shuffle=True),\n",
       "                     estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bynode=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None, feature_types=None,\n",
       "                                             gamma=None, grow_policy=None,\n",
       "                                             importa...\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None, max_depth=None,\n",
       "                                             max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             multi_strategy=None,\n",
       "                                             n_estimators=None, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             random_state=None, ...),\n",
       "                     n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'n_estimators': [5, 10, 25, 50]},\n",
       "                     random_state=123, scoring='accuracy', verbose=10),\n",
       "  'train_cm': array([[57,  0,  0,  0],\n",
       "         [ 0, 57,  0,  0],\n",
       "         [ 0,  0, 57,  0],\n",
       "         [ 0,  0,  0, 57]], dtype=int64),\n",
       "  'valid_cm': array([[ 8,  0,  0,  0],\n",
       "         [ 0, 23,  0,  0],\n",
       "         [ 0,  0, 30,  1],\n",
       "         [ 1,  0,  2, 24]], dtype=int64),\n",
       "  'train_accuracy': 1.0,\n",
       "  'valid_accuracy': 0.9550561797752809,\n",
       "  'best_params': {'n_estimators': 25}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(return_file=True):\n",
    "    \"\"\"Function to get the best model based on validation accuracy\"\"\"\n",
    "    # Load tuned model\n",
    "    list_of_tuned_model = utils.pickle_load(CONFIG_DATA['list_of_tuned_model_path'])\n",
    "\n",
    "    # Get the best model based on validation accuracy\n",
    "    best_model_name = None\n",
    "    best_model = None\n",
    "    best_performance = -1  # Initialize to -1 since accuracy cannot be negative\n",
    "    best_model_param = None\n",
    "\n",
    "    for model_name, model_info in list_of_tuned_model.items():\n",
    "        # Extract validation accuracy\n",
    "        valid_accuracy = model_info['valid_accuracy']\n",
    "        \n",
    "        if valid_accuracy > best_performance:\n",
    "            best_model_name = model_name\n",
    "            best_model = model_info['model']\n",
    "            best_performance = valid_accuracy\n",
    "            best_model_param = model_info['best_params']\n",
    "\n",
    "    # Dump the best model\n",
    "    utils.pickle_dump(best_model, CONFIG_DATA['best_model_path'])\n",
    "\n",
    "    # Print the summary of the best model\n",
    "    print('=============================================')\n",
    "    print('Best model        :', best_model_name)\n",
    "    print('Validation accuracy:', best_performance)\n",
    "    print('Best model params :', best_model_param)\n",
    "    print('=============================================')\n",
    "\n",
    "    if return_file:\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Best model        : XGBClassifier\n",
      "Validation accuracy: 0.9550561797752809\n",
      "Best model params : {'n_estimators': 25}\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "best_model = get_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = utils.pickle_load(CONFIG_DATA['test_clean_path'][0])\n",
    "y_test = utils.pickle_load(CONFIG_DATA['test_clean_path'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[26  0  0  0]\n",
      " [ 0 21  0  0]\n",
      " [ 1  0 25  0]\n",
      " [ 1  0  1 36]]\n",
      "Accuracy: 0.972972972972973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Predict\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Optional: Calculate accuracy from the confusion matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix and accuracy\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972972972972973"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2, 3, 3, 3, 0, 3, 2, 3, 3, 2, 3, 2, 0, 2, 0, 0, 3, 3, 3,\n",
       "       0, 1, 1, 2, 1, 2, 0, 1, 1, 3, 2, 3, 3, 2, 2, 2, 2, 0, 3, 0, 1, 0,\n",
       "       0, 2, 2, 1, 1, 1, 2, 3, 3, 1, 1, 0, 3, 2, 2, 1, 3, 2, 0, 0, 2, 1,\n",
       "       0, 1, 3, 0, 2, 0, 0, 3, 1, 3, 0, 3, 2, 0, 1, 2, 2, 3, 3, 1, 0, 3,\n",
       "       0, 3, 3, 1, 3, 3, 3, 3, 0, 0, 1, 0, 0, 1, 3, 3, 2, 0, 0, 3, 2, 3,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231    0\n",
       "374    3\n",
       "55     1\n",
       "381    3\n",
       "70     3\n",
       "      ..\n",
       "11     3\n",
       "281    3\n",
       "22     2\n",
       "375    3\n",
       "477    2\n",
       "Name: category_encoded, Length: 111, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'user_id': X_test['customer_id'],\n",
    "    'y_pred': y_pred,\n",
    "    'y_test': y_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  y_pred  y_test\n",
       "231       11       0       0\n",
       "374        6       3       3\n",
       "55        16       1       1\n",
       "381       15       2       3\n",
       "70        13       3       3\n",
       "..       ...     ...     ...\n",
       "11        19       0       3\n",
       "281        9       3       3\n",
       "22         7       2       2\n",
       "375        4       3       3\n",
       "477       19       2       2\n",
       "\n",
       "[111 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  y_pred  y_test\n",
       "231       11       0       0\n",
       "374        6       3       3\n",
       "55        16       1       1\n",
       "381       15       2       3\n",
       "70        13       3       3\n",
       "..       ...     ...     ...\n",
       "11        19       0       3\n",
       "281        9       3       3\n",
       "22         7       2       2\n",
       "375        4       3       3\n",
       "477       19       2       2\n",
       "\n",
       "[111 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "dari data dummy disimpulkan sebetulnya bisa dijadika 2 use case:\n",
    "1. Binary classification: Apakah pelanggan tertentu akan melakukan pembelian dalam periode tertentu atau tidak.\n",
    "2. Multiclass classification: Produk apa yang akan dibeli oleh pelanggan."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
